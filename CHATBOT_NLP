!pip install -q numpy pandas scikit-learn matplotlib seaborn transformers datasets torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder
from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments
import torch






df = pd.read_csv("https://huggingface.co/datasets/kkotkar1/course-reviews/resolve/main/reviews.csv")





df = df.dropna()
df = df.drop_duplicates()





x = df['review'].tolist()
y = df['label'].tolist()




le = LabelEncoder()
y_encoded = le.fit_transform(y)




print("\nSentiment Class Distribution:")
print(df['label'].value_counts())




from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)







tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased")





train_encodings = tokenizer(x_train, truncation=True, padding=True, max_length=128)
test_encodings = tokenizer(x_test, truncation=True, padding=True, max_length=128)






class ReviewsDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels
    def __len__(self):
        return len(self.labels)
    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item["labels"] = torch.tensor(self.labels[idx])
        return item






train_dataset = ReviewsDataset(train_encodings, y_train)
test_dataset = ReviewsDataset(test_encodings, y_test)






num_labels = len(np.unique(y_encoded))
model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=num_labels)





args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    learning_rate=2e-5,
    weight_decay=0.01,
    logging_dir="./logs",
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    tokenizer=tokenizer,
)






print("\nStarting model training...")
trainer.train()
print("Training complete.")
print("\nEvaluating model performance...")
preds = trainer.predict(test_dataset)
y_pred = np.argmax(preds.predictions, axis=1)
print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, target_names=le.classes_))







cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()







review = "This course was absolutely terrible and a huge waste of my time."
inputs = tokenizer(review, return_tensors="pt", truncation=True, padding=True, max_length=128)
outputs = model(**inputs)
prediction = torch.argmax(outputs.logits, dim=1).item()
sentiment = le.inverse_transform([prediction])[0]
print("\n--- Single Example Prediction ---")
print(f"Review: '{review}'")
print(f"Predicted Sentiment: {sentiment}")
